#' Minnesota prior
#'
#'Generates dummy observations for a Minnesota prior on a VAR.
#'
#' Output of this function is used in `rfmdd(}` and `sfmdd()`, and can
#' be used with `rfvar()`.
#'
#' The Minnesota prior is a normal distribution on the model's coefficients,
#' generated by "dummy observations".  The mean of the distribution is
#' determined by `OwnLagMeans'.  All coefficients have zero prior mean except
#' some "own lag" coefficients and possibly the constant term.  `OwnLagMeans`
#' can be a single number (usually 1), in which case that number is the prior
#' mean of the first lag on variable i in equation i for every i.  It can also
#' be a vector of length m, in which case it is the prior mean of the
#' coefficients on lags 1 #' through m, of variable i in equation i, for every
#' i.  Finally it can be an `nv x m` matrix, in which the i'th row is the
#' prior mean of coefficient on lags 1 through m in equation i.
#' 
#' \subsection{lambda, mu}{ The weight on prior beliefs that when all (resp.
#' own) lagged variables have been constant, current variables will persist at #' the
#' same value.  `lambda < 0` implies the constant term is not included in the
#' corresponding dummy observation (usually not a good idea.) Setting either to
#' NULL eliminates the corresponding dummy observations.}
#' \subsection{`xsig`}{Scale of variation in the `x` variables.  Used to create
#' dummy observations pulling their coefficients toward zero.  The last element
#' of `x` is the constant.  Its `xsig` value can be set to zero to avoid the
#' prior's pulling toward zero means.
#' \subsection{`ybar`} By default `ybar` is set to the mean of the initial
#' conditions vector.  Setting `ybar` as non-NULL overrides that.  The `lambda`
#' and `mu` dummy observations use `ybar` and (possibly) `xbar` as the
#' persistent levels.}
#' \subsection{OwnLagMeans} If a single numeric value, the prior mean of the
#' first own lag coefficient in all equations.  If a numeric vector of length
#' m, the prior mean of the first m lag coefficients in all equations.  If a
#' `nv` by m matrix, the prior means of the first m lags in all equations,
#' possibly varying across equations.
#'
#' The default is close to the optimal second-order univariate AR coefficients
#' when the variable is a unit-averaged continuous time Wiener process.  This
#' works well for variables like GDP or investment, which cumulate through time.
#' For data that are sampled rather than averaged, like some financial or price
#' data, `OwnLagMeans=1` is better.  For non-persistent or differenced variables,
#' `OwnLagMeans=0` might be better.  
#'
#' `lambda` and `mu` actually pull the prior toward "persistence" only when
#' the sum of coefficients on the own lag is one.  Otherwise they just pull
#' toward `sum(OwnLagMeans) * ybar + const = ybar`.  In all cases, though, the `lambda`
#' and `mu` components make the prior tighter on sums of coefficients than on
#' individual coefficents.
#'
#' @param nv number of endogenous variables
#' @param nx number of exogenous variables
#' @param lags number of lags
#' @param tight Weight on the individual coefficient Minnesota prior
#'              dummies.  Prior std dev on first lag is \code{1/tight}
#' @param decay Prior std dev of coefficients declines at rate `1/lag^decay`.
#' @param sig  Modal prior std deviations of resituals.  This vector
#'             is used to scale other parts of the prior, even when there
#'             are no dummy observations aimed at residual variances (w==0).
#' @param w Weight on dummy observations pulling residual std deviations
#'          toward `sig`.
#' @param lambda Weight on "co-persistence" dummy observations.
#' @param mu Weight on individual variable persistence dummy observations.
#' @param xsig Rough scale of variation in \code{x} variables.  
#' @param ybar scale of persistence dummy observations
#' @param xbar scale of persistence dummy observation \code{x} values
#' @param OwnLagMeans prior expectation of own lag coefficients.  See details.
#'
#' @return \item{ydum}{dummy observations on y}
#'         \item{xdum}{dummy observations on x}
#'         \item{pbreaks}{locations of breaks in the dummy observations}
#' @md
#' @export
varprior <-
    function(nv=1,nx=0,lags=1,tight=5, decay=.5, sig=rep(.01, nv), w=1,
             lambda=5, mu=1, xsig=NULL,
             ybar=NULL, xbar=1, OwnLagMeans=c(1.25, -.25))
### ydum, xdum:   dummy observation data that implement the prior
### breaks:       vector of points in the dummy data after which new dummy obs start
###                   Set breaks=T+matrix(c(0,breaks),ncol=1), ydata=rbind(ydata,ydum), xdum=rbind(xdata,xdum), where 
###                   actual data matrix has T rows, in preparing input for rfvar3
### nv,nx,lags: VAR dimensions
### mnprior$tight:Overall tightness of Minnesota prior. 1/tight ~ own lag std dev
### mnprior$decay:Standard deviations of lags shrink as lag^(-decay)
### vprior$sig:   Vector of prior modes for square roots of diagonal elements of r.f. covariance matrix
###                  Names of this vector name columns of output ydum.
### vprior$w:     Weight on prior on vcv.  1 corresponds to "one dummy observation" weight
###                   vprior$sig is needed
###                   to scale the Minnesota prior, even if the prior on sigma is not used itself.
###                   Set vprior$w=0 to achieve this.
###                   mnprior and vprior.w can each be set to NULL, thereby eliminating the corresponding
###                   dummy observations.
### xsig:          Rough scale of x variances.  names of this vector name output xdum
### urprior:       Parameters of the "unit roots" and "co-persistence" priors that are
###                   implemented directly in rfvar3.  lambda and mu should be NULL here if
###                   the dummy observations generated here are used with rfvar3 and lanbda and mu
###                   are not NULL in rfvar3.   lambda < 0 means x'st not included.  Note that constant
###                   is assumed to be last element of x.  If you want lambda < 0 to be the only source
###                   of a prior on the constant, but xsig is not null, set the last element of xsig
###                   to zero.  
### ybar,xbar:        estimates of data means, used in constructing urprior component, but not otherwise.
###                   The default xbar=1 is correct when the constant is the only x.    
### nstat:         Set components corresponding to non-persistent variables to FALSE.
### Note:          The original Minnesota prior treats own lags asymmetrically, and therefore
###                   cannot be implemented entirely with simple dummy observations.  It is also usually
###                   taken to include the sum-of-coefficients and co-persistence components
###                   that are implemented directly in rfvar3.R.  The diagonal prior on v, combined
###                   with sum-of-coefficients and co-persistence components and with the unit own-first-lag
###                   prior mean generates larger prior variances for own than for cross-effects even in 
###                   this formulation, but here there is no way to shrink toward a set of unconstrained 
###                   univariate ARs.
###-----------------------
###
{ require(abind)
    ## nx=0 case messes up, at least at the end (2012.9.23)
    if (!is.null(tight))
    { ## single-coefficient prior dummy obs.
        ## each vbl and each lag has a dummy observation, and each dummy obs has values for current and lagged
        ## y's  and current x's. we separate the y's and the x's into two arrays.  The last two indexes, lag
        ## and rhsy, index the dummy observations.  
        xdum <- if(nx > 0) {
                    array(0, dim=c(lags + 1, nx, lags, nv), dimnames=list(obsno=1:(lags + 1), xvbl=1:nx, lag=1:lags, rhsy=1:nv))
                } else {
                    NULL
                }
        ydum <- array(0,dim=c(lags+1,nv,lags,nv),dimnames=list(obsno=1:(lags+1),rhsy=1:nv,lag=1:lags, rhsy=1:nv))
        for (il in 1:lags)
        {
            ##-----debug---------
            ## browser()
            ##------------------
            ydum[il+1,,il,] <- il^decay*diag(sig,nv,nv)
        }
        ## If we have non-trivial x's, need dobs's for them, also.
        if(!is.null(xsig)) {
            ydumx <-  array(0, dim=c(lags + 1, nv, nx), dimnames=list(obsno=1:(lags + 1), rhsy=1:nv, dx=1:nx))
            xdumx <-  array(0, dim=c(lags + 1, nx, nx), dimnames=list(obsno=1:(lags + 1), xvbl=nx, dx=1:nx))
            xdumx[1, , ] <- diag(xsig, nx, nx)
            ## note that xvalues for obsno 2:(lags+1) don't matter.  This is one dummy obseervation,
            ## so only the "current" x is used.
        }
        if (is.matrix(OwnLagMeans)) {
            nown <- dim(OwnLagMeans)[2]
            if (nown < lags) {
                OwnLagMeans <- cbind(OwnLagMeans, matrix(0, nv, lags - nown))
            }
        } else if ( is.vector(OwnLagMeans)) {
            nown <- length(OwnLagMeans)
            OwnLagMeans <- matrix(c(rep(OwnLagMeans, each=nv), rep(0, (lags - nown) * nv)),
                                  nv, lags)
        } else {
            OwnLagMeans <-
                matrix(c(rep(OwnLagMeans, nv), rep(0, nv * (lags - 1))), nv, lags)
        }
        ## ydum[1,,1,] <- diag(vprior$sig * nstat, nv, nv) # so own lag has mean zero if nstat FALSE
        for (jv in 1:nv) {
            ydum[1, jv, , jv] <- sig[jv] * OwnLagMeans[jv, ] #
        }
        ydum <- tight * ydum
        dim(ydum) <- c(lags+1,nv,lags*nv)
        ydum <- ydum[seq(lags+1,1,by=-1),,]
        xdum <- tight*xdum
        dim(xdum) <- c(lags+1,nx,lags*nv)
        xdum <- xdum[seq(lags+1,1,by=-1),,]
    } else {
        ydum <- NULL;
        xdum <- NULL;
        breaks <- NULL;
    }
    if (!is.null(lambda) ) {
        ## lambda obs.  just one
        ydumur <- matrix(ybar, nrow=lags+1, ncol=nv, byrow=TRUE) * abs(lambda)
        ## ydumur[1, ] <- apply(OwnLagMeans, 1, sum) * ybar
        ## Line above would preserve 0 mean for x coefficients even when
        ## sum(OwnLagMeans) < 1, which does not make sense.
        ydumur <- array(ydumur, c(dim(ydumur), 1))
        if(lambda > 0) {
            xdumur <- matrix(xbar, lags + 1, nx, byrow=TRUE) * lambda # (all but first row redundant)
        } else {
            xdumur <- matrix(0, lags + 1, nx)
        }
    } else {
        ydumur <- NULL
        xdumur <- NULL
    }
    if (!is.null(mu)) {
        ## 
        ydumuri <-array(0, c(lags+1, nv, nv))
        if ( mu > 0) {
            xdumuri <- matrix(xbar, lags+1, nx, byrow=TRUE)
        } else {
            xdumuri <- matrix(0, lags+1, nx)
        }
        ## sumOLM <- apply(OwnLagMeans, 1, sum)
        for (iv in 1:nv) {
            ## ydumuri[-1 , iv, iv] <- ybar[iv]
            ## ydumuri[1, iv, iv] <- (sumOLM * ybar)[iv]
            ## Here again, we want to pull the unconditional
            ## mean toward ybar when sumOLM < 1, which deleted code
            ## above prevents.
            ydumuri[ , iv, iv] <- ybar[iv]
        }
        ydumur <- abind(ydumur, mu * ydumuri, along=3)
        xdumur <- abind(xdumur, mu * xdumuri, along=3)
    }
    if (!is.null(w))
    {
        ydum2 <- array(0,dim=c(lags+1,nv,nv))
        xdum2 <- array(0,dim=c(lags+1,nx,nv))
        ydum2[lags+1,,] <- diag(sig,nv,nv) * w 
    } else {
        ydum2 <- NULL
        xdum2 <- NULL
    }
    ## stack everything up.
    dim(ydum) <- c(lags + 1, nv, lags * nv) # merge all the individual mn dobs
    dim(xdum) <- c(lags + 1, nx, lags * nv)
    ydum <- abind(ydum, ydumur, ydum2, along=3)
    xdum <- abind(xdum, xdumur, xdum2, along=3)
    breaks <- (lags+1) * (1:(dim(ydum)[3] -1)) # end of sample is not a "break".
    ydum <- aperm(ydum, c(1, 3, 2))
    ydum <- matrix(ydum, ncol=dim(ydum)[3])
    xdum <- aperm(xdum, c(1,3,2))
    xdum <- matrix(xdum, ncol=dim(xdum)[3])
    ##   dim(ydum2) <- c((lags+1)*nv,nv)
    ##   dim(ydum) <- c((lags+1)*nv,lags*nv)
    ##   ydum <- cbind(ydum,ydum2)
    ##   dim(xdum2) <- c((lags+1)*nx,nv)
    ##   dim(xdum) <- c((lags +1)*nx,lags*nv)
    ##   xdum <- cbind(xdum,xdum2)
    ##   dim(ydum) <- c(lags+1,nv,dim(ydum)[2])
    ##   ydum <- aperm(ydum,c(1,3,2))
    ##   dim(ydum) <- c(dim(ydum)[1]*dim(ydum)[2],nv)
    ##   dim(xdum) <- c(lags+1,nx,dim(xdum)[2])
    ##   xdum <- aperm(xdum,c(1,3,2))
    ##   dim(xdum) <- c(dim(xdum)[1]*dim(xdum)[2],nx)
    ##   if(nv>1){
    ##     breaks <- c(breaks, (lags+1)*(0:(nv-1))+lbreak)
    ##   }
    ## } else {
    ##   if (!is.null(ydum)) { # case with mnprior non-null, but vprior null
    ##     ydum <- aperm(ydum, c(1, 3, 2))
    ##     dim(ydum) <- c(prod(dim(ydum)[1:2]), dim(ydum)[3])
    ##     xdum <- aperm(xdum, c(1,3,2))
    ##     dim(xdum) <- c(prod(dim(xdum)[1:2]), dim(xdum)[3])
    ##   }
    ## }
    dimnames(ydum) <- list(NULL, names(sig))
    dimnames(xdum) <- list(NULL, names(xsig))
    return(list(ydum=ydum,xdum=xdum,pbreaks=breaks))
    ## data here in the form of T by nv y, and T x nx x.  Lagged y's not put in to a rhs
    ## regression matrix, so a "breaks" vector is needed.  
    ## rfvar3 adds persistence and sum of coeffs dummy observations at end of  data in lhs and rhs
    ## regression matrix form.  So to combine this with rfvar3, set lambda and mu to NULL in one or the
    ## other program.
}
